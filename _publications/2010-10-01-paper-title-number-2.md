---
title: "LPF-Defense: 3D Adversarial Defense based on Frequency Analysis"
collection: publications
permalink: /publication/lpf-defense
excerpt: 'Although 3D point cloud classification has recently been widely deployed in different application scenarios, it is still very vulnerable to adversarial attacks. This increases the importance of robust training of 3D models in the face of adversarial attacks. Based on our analysis on the performance of existing adversarial attacks, more adversarial perturbations are found in the mid and high-frequency components of input data. Therefore, by suppressing the high-frequency content in the training phase, the models robustness against adversarial examples is improved. Experiments showed that the proposed defense method decreases the success rate of six attacks on PointNet, PointNet++, and DGCNN models. In particular, improvements are achieved with an average increase of classification accuracy by 3.8 % on drop100 attack and 4.26 % on drop200 attack compared to the state-of-the-art methods. The method also improves models accuracy on the original dataset compared to other available methods.


[Paper](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0271388)**.**[Code](https://github.com/kimianoorbakhsh/LPF-Defense)'
date: 2022-02-23
venue: 'PLOS ONE'
paperurl: ''
citation: 'Naderi, H., Noorbakhsh, K., Etemadi, A., & Kasaei, S. (02 2023). LPF-Defense: 3D adversarial defense based on frequency analysis. PLOS ONE, 18(2), 1–19. doi:10.1371/journal.pone.0271388'
---
Although 3D point cloud classification has recently been widely deployed in different application scenarios, it is still very vulnerable to adversarial attacks. This increases the importance of robust training of 3D models in the face of adversarial attacks. Based on our analysis on the performance of existing adversarial attacks, more adversarial perturbations are found in the mid and high-frequency components of input data. Therefore, by suppressing the high-frequency content in the training phase, the models robustness against adversarial examples is improved. Experiments showed that the proposed defense method decreases the success rate of six attacks on PointNet, PointNet++, and DGCNN models. In particular, improvements are achieved with an average increase of classification accuracy by 3.8 % on drop100 attack and 4.26 % on drop200 attack compared to the state-of-the-art methods. The method also improves models accuracy on the original dataset compared to other available methods.

[Download paper here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0271388)

Recommended citation: Naderi, H., Noorbakhsh, K., Etemadi, A., & Kasaei, S. (02 2023). LPF-Defense: 3D adversarial defense based on frequency analysis. PLOS ONE, 18(2), 1–19. doi:10.1371/journal.pone.0271388.